{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeurErrors : Accessing segmentation errors and predicting error nodes at the L2 level\n",
    "\n",
    "This tutorial provides a high-level overview for how to access FlyWire's error dataset on top of CAVEclient built from [connectome annotation versioning engine](https://www.biorxiv.org/content/10.1101/2023.07.26.550598v1.abstract).\n",
    "\n",
    "CAVE supports proofreading of datasets and their analysis even while proofreading is ongoing.\n",
    "\n",
    "NeurErrors is a Python package that allows you to visualize and analyze the errors found by the proofreaders in the segmented connectome. One part is data acquisition of found errors for any segment ID in time. The other part focuses on building a graph dataset at the L2 resolution of the chunked graph and associating error coordinates to each node of the graph for Graph Machine Learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing NeurErrors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install NeurErrors, you can use the following command:\n",
    "\n",
    "`pip install https://github.com/raphaellevisse/NeurErrors.git`\n",
    "\n",
    "Inside a notebook, you can import NeurErrors with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/raphaellevisse/NeurErrors.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you have an account on CaveClient which is core to the NeurErrors package and allows you to access and query the chunked graph. Here is the link to the [CaveClient tutorial](https://github.com/seung-lab/FlyConnectome/blob/main/CAVE%20tutorial.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neurerrors\n",
    "import caveclient\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch_geometric\n",
    "import tqdm\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then start a session with the CAVEclient and we will use the `Dataset_Client` class to build the error and the graph dataset associated. Both can be independently built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_id = [720575940638929825]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Caveclient initialization ###\n",
    "datastack_name = \"flywire_fafb_public\"\n",
    "voxel_resolution = np.array([16,16,40])\n",
    "\n",
    "client = caveclient.CAVEclient(datastack_name)\n",
    "#client.materialize.version = 783 # FlyWire public version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NeurErrors Dataset Client initialization (client is optional if you want to use the other functions of the Dataset_Client class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_client = neurerrors.Dataset_Client(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional:\n",
    "Generally, one has a .txt file of the segment IDs he wants to verify. One function of the `Dataset_Client` class is to build the old segment IDs from this file.\n",
    "This will return a dictionary of the root segment IDs and the list of old segment IDs associated to each root segment ID. The minimum size of the segment to be considered is set to 10 L2 leaves (argument `min_l2_size`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'neurerrors/data/seg_ids/ID_tests.txt'\n",
    "root_to_old_seg_ids, old_seg_ids = dataset_client.get_old_seg_ids_from_txt_file(input_path, min_l2_size=10, show_progress=True)\n",
    "print(root_to_old_seg_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build the graph dataset as a list of PyTorch Geometric Data objects, one can use the following function and build the feature list of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old_seg_ids = [720575940620826450] # Example with one old segment ID\n",
    "attributes_list = ['rep_coord_nm', 'size_nm3', 'area_nm2', 'max_dt_nm', 'mean_dt_nm', 'pca_val']\n",
    "graph_dataset = dataset_client.build_graph_dataset(old_seg_ids, attributes_list, show_progress=True, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph dataset is just a list of Data objects of the neurons as graphs of L2 nodes. We can add the error features to the dataset by making a forward pass in the graph of operations.\n",
    "associate_error_to_graph_dataset will find all proofreading actions on the neuron, find their amplitude and assimilate them to the closest L2 node in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_client.associate_error_to_graph_dataset(graph_dataset, voxel_resolution=voxel_resolution, show_progress=True) # you can add find_operation_weights=True to find the weights of the operations, but this adds a big time cost\n",
    "#dataset_client.normalize_features(graph_dataset, flywire_normalization=True) #if you want to normalize the features for more stable training, normalizes data.x (features) to have a mean of 0 and a std of 1. \n",
    "# Standard normalization over 20,000 neurons of Flywire public dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now visualize the dataset with the following functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FlyWire\n",
    "data_point = graph_dataset[1]\n",
    "print(data_point)\n",
    "url = dataset_client.get_url_for_visualization(seg_id=data_point.metadata['seg_id'], error_features=data_point.error_features, voxel_resolution=voxel_resolution, local_host=True)\n",
    "# CA3\n",
    "# url = dataset_client.get_url_for_visualization(seg_id=data_point.metadata['seg_id'], em_data_url=em_data_url_ca3, segmentation_url=segmentation_url_ca3, error_features=data_point.error_features, voxel_resolution=voxel_resolution, local_host=True)\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making decisions on the dataset\n",
    "\n",
    "With these graph datasets, one can now train a model to make decisions on the errors. There is already a pretrained model on the FlyWire public dataset that can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_decisions = dataset_client.model_inference([graph_dataset[0]], threshold=0.5, pretrained_weights_path=\"neurerrors/models/training/weights/19000-256-best-3_5.pt\")\n",
    "#print(node_decisions)\n",
    "predicted_l2_nodes = graph_dataset[0].l2_nodes[node_decisions]\n",
    "print(predicted_l2_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = dataset_client.get_url_for_visualization(seg_id=graph_dataset[0].metadata['seg_id'], error_features=graph_dataset[0].error_features, local_host=True, l2_nodes=predicted_l2_nodes)\n",
    "print(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
